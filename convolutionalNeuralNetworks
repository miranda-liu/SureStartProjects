Link: https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks 
Architecture of a traditional CNN:
    -Input image -> convolutions -> pooling -> fully connected


Convolution layer (CONV)
    -Uses filters that perform convolution operators as it is scanning the input I with respect to its dimensions
    -Hyperparameters are variables that determine the network's structure (ex: number of hidden units) and 
     determine how the network is trained(ex: learning rate)
    -CONV's hyperparameters include filter size F and stride S
    -The output O is called a feature/activation map

Pooling (POOL)
    -A downsampling operation that does spacial invariance
    -Max and avg pooling are special kinds where the max and avg values are taken
    

Fully connected (FC)
    -Operates on a flattened input wher each input is connected to all the neurons
    -Usually found towards end of CNN architectures + can be used to optimize objectives

Filter hyperparameters
    -Dimensions of a filter
        -A filter of size F x F applied to an input containing C channels is a F x F x C volume that performs
         convolutions on an input of size I x I x C
        -Produces an output feature map of O x O x 1
    -Stride 
        -For a convolutional or pooling operation, the stride S is the # of pixels the window moves after each operation
    
    -Zero-padding
        -Denotes the process of adding P zeroes to each side of the boundaries of the input
-Can be manually specified or automatically set through a mode          

Tuning hyperparameters
    -Parameter compatability in convolution layer
        -Output size
            -I = length of input volume size, F = length of filter, P = amt of zero padding, S = stride

    -Understanding the complexity of the model
        -Useful to determine number of parameters that the architecture will have
        -Receptive field
            -At layer k, denoted by R_k x R_k of the input that each pixel of the k-th activation map can see
            -Calling F_j = filter size of layer j, S_i = stride value of layer i, S_0 = 1
            -Receptive field at layer k







Commonly used activation functions
    -Rectified linear unit (ReLU)
        -An activation function g that is used on all elements of the volume
        -Aims to introduce non-linearities to the network
        -Three variants

    -Softmax
        -This step can be seen as a generalized logistic function that takes as input a vector of scores x in R^n and outputs a vector output probability p in R^n through a softmax function at the end of the architecture











Object detection
    -Types of models
        -Three main ones for object recognition algorithms

    -Detection 
        -Different methods are used depending on whether you want to just locate the object or detect a more
         complex shape
        -Two main ones
















    -Intersection over union (IoU)
        -A function that quantifies how correctly positions a predicted bounding box, B_p, is over the actual bounding box B_a
        -Always between 0 and 1, considered good if greater than or equal to 0.5

    -Anchor boxes
        -A technique used to predict overlapping bounding boxes
        -In practice, the network can predict more than one box at the same time, where each prediction is constrained
         to have a given set of geometrical properties
    -Non-max suppression
        -This technique aims to remove duplicate overlapping boundary boxes of a same object by selecting the most representative ones
        -After removing all boxes with a probability prediction < 0.6, these steps are repeated while boxes remain
            -Step 1: pick the box w the largest prediction probability
            -Step 2: discard any box having an IoU >= 0.5 w the previous box

    -You only look once (YOLO)
        -An object detection algorithm that
            -Step 1: divide the input image into a G x G grid 
            -Step 2: for each grid cell, run a CNN that predicts y of the following form

                -p_c is the probability of detecting an object
                -b_x, b_y, b_h, b_w are properties of the detected boundary box
                -c_1, ..., c_p is a one-hot rep of which of the p classes were detected
                -k is the number of anchor boxes
            -Step 3: run the non-max suppression algorithm to remove any potential duplicate overlapping boundary boxes

    -Region w convolution neural networks (R-CNN)
        -An object detection algorithm that first segments the image to find potential relevant bounding boxes 
        -Then runs the detection algorithm to find the most probable objects in those bounding boxes


Face verification and recognition
    -Types of models 
        -Two main Types












    -One shot learning
        -A face verification algorithm that uses a limited training set to learn a similarity function that quantifies
         how diff 2 given images are
        -The similarity function is often noted as d(image1, image2) when applied to 2 images
    -Siamese network
        -These aim to learn how to encode images to then quantify how diff 2 images are
        -For a given input image x^(i), the encoded output is often noted as f(x^(i))
    -Triplet loss
        -A loss function computed on the embedding representation of a triplet of images
            -A (anchor), P (positive), N (negative)
            -A and P belong to the same class, N to another
            -a is the margin parameter 
        -Defined as


Neural style transfer
    -Motivation
        -The goal of neural style transfer is to generate an image G based on a given content C and given style s
    -Activation 
        -In a given layer l, the activation is noted a^[l] and is of dimensions n_H x n_w x n_c
    -Content cost function
        -J_content(C, G) is used to determine how the generated image G differs from the og content image Calling
        -Defined as

    -Style matrix
        -G^[l] of a given layer l is a Gram matrix where each of its elements G^[l]_kk' quantifies how correlated the
         channels k and k' are
        -Defined as w respect to activates a^[l]

    -Style cost function
        -J_style(S, G) is used to determine how the generated image G differs from the style S 
        -Defined as

    -Overall cost function
        -Defined as being a combo of the content and style cost functions, weighted by parameters a and B_a











Architectures using computational tricks
    -Generative adversarial network (GAN)
        -Composed of a generative and discriminative model
        -Generative model aims to generate the most truthful output that is fed into the discriminative which aims to differentiate the generated and true image

    -Residual network (ResNet)
        -Uses residual blocks w a high number of layers meant to decrease the training error
        -Equation is

    -Inception network
        -Uses inception modules and aims at giving a try at different convolutions to increase its performance through diversification
        -Uses the 1 x 1 convolution trick to limit the computational burden

