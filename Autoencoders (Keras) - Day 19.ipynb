{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples\n",
    "    # the compression and decompression functions are implemented with neural networks\n",
    "    # data-specific = can only compress data similar to what it's been trained on\n",
    "    # lossy = decompressed outputs are degraded compared to the original inputs\n",
    "    # learned automatically = easy to train specialized instances of the algorithm that perform will on a specific type of input\n",
    "\n",
    "# to build an autoencoder: encoding function, decoding function, and a distance function between the amount of info loss between compressed representation of data and decompressed representation\n",
    "\n",
    "# some applications are data denoising and dimensionality reduction for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "# encoder and decoder are single fully-connected layers\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "# encoder model\n",
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "# decoder model\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the binary crossentropy loss function and Adam optimizer\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "# discard the labels since it's only interested in encoding/decoding the input images\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# normalize values between 0 and 1, and flatten the 28x28 images into vectors of size 784\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 3s 9ms/step - loss: 0.3856 - val_loss: 0.18830s - loss: \n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1782 - val_loss: 0.1528\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1488 - val_loss: 0.1339\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1318 - val_loss: 0.1215\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1205 - val_loss: 0.1132\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1130 - val_loss: 0.1077\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1078 - val_loss: 0.1034\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1040 - val_loss: 0.0999\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1005 - val_loss: 0.0974\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0981 - val_loss: 0.0957\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.0944\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0952 - val_loss: 0.0936\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0946 - val_loss: 0.0931\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0943 - val_loss: 0.0928\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0939 - val_loss: 0.0924\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0937 - val_loss: 0.0923\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0934 - val_loss: 0.0920\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0933 - val_loss: 0.0918\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0916\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0926 - val_loss: 0.0917\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0925 - val_loss: 0.0915\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0925 - val_loss: 0.0916\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0925 - val_loss: 0.0915\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0928 - val_loss: 0.0915\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0924 - val_loss: 0.0914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24038053b20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the autoencoder\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the reconstructed inputs and the encoded representations with matplotlib\n",
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# top row is original digits, bottom row is reconstructed digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3935 - val_loss: 0.1944\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1856 - val_loss: 0.1614\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1576 - val_loss: 0.1421\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1405 - val_loss: 0.1308\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1299 - val_loss: 0.1231\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1230 - val_loss: 0.1178\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1179 - val_loss: 0.1137\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1142 - val_loss: 0.1107\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1114 - val_loss: 0.1086\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1094 - val_loss: 0.1071\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.1059\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1069 - val_loss: 0.1051\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1062 - val_loss: 0.1044\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1055 - val_loss: 0.1038\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1047 - val_loss: 0.1033\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1045 - val_loss: 0.1029\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1043 - val_loss: 0.1025\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.1022\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1033 - val_loss: 0.1019\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1032 - val_loss: 0.1017\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1028 - val_loss: 0.1014\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1025 - val_loss: 0.1012\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1009\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1022 - val_loss: 0.1007\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1019 - val_loss: 0.1005\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1016 - val_loss: 0.1003\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1014 - val_loss: 0.1002\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.1000\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1012 - val_loss: 0.0999\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1009 - val_loss: 0.0997\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.0996\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.0994\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1006 - val_loss: 0.0993\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.0992\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1002 - val_loss: 0.0992\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1001 - val_loss: 0.0990\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1004 - val_loss: 0.0989\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0998 - val_loss: 0.0988\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0999 - val_loss: 0.0987\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0996 - val_loss: 0.0986\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0998 - val_loss: 0.0985\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0998 - val_loss: 0.0984\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0994 - val_loss: 0.0983\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.0983\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0994 - val_loss: 0.0981\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.0981\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.0981\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0993 - val_loss: 0.0979\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0992 - val_loss: 0.0979\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.0978\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0989 - val_loss: 0.0978\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.0977\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.0976\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.0976\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.0975\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.0975\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.0974\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.0973\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0984 - val_loss: 0.0973\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.0973\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.0972\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.0971\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.0971\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0982 - val_loss: 0.0970\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0980 - val_loss: 0.0970\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.0970\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0979 - val_loss: 0.0969\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0968\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0968\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0967\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0967\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.0966\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.0965\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.0965\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.0964\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0975 - val_loss: 0.0963\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.0963\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.0962\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0976 - val_loss: 0.0962\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0962\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0962\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0961\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.0961\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.0960\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.0960\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0960\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0969 - val_loss: 0.0961\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.0959\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.0959\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.0958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24040696100>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a sparsity constraint on the encoded representations\n",
    "    # means that fewer units fire at a given time\n",
    "    # done through adding an activity_regularizer to the Dense layer in Keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# Add a Dense layer with a L1 activity regularizer\n",
    "encoded = layers.Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# top row is original digits, bottom row is reconstructed digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.3349 - val_loss: 0.1628\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1543 - val_loss: 0.1338\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1309 - val_loss: 0.1213\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.1206 - val_loss: 0.1145\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1143 - val_loss: 0.1096\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1099 - val_loss: 0.1063\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1067 - val_loss: 0.1033\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1041 - val_loss: 0.1014\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1019 - val_loss: 0.0994\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1003 - val_loss: 0.0985\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0989 - val_loss: 0.0970\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0975 - val_loss: 0.0960\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0966 - val_loss: 0.0947\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0954 - val_loss: 0.0938\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0943 - val_loss: 0.0932\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0937 - val_loss: 0.0929\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0932 - val_loss: 0.0916\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0916 - val_loss: 0.0904\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0911 - val_loss: 0.0900\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0906 - val_loss: 0.0896\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0901 - val_loss: 0.0893\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0898 - val_loss: 0.0887\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0893 - val_loss: 0.0886\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0892 - val_loss: 0.0877\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0885 - val_loss: 0.0874\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0881 - val_loss: 0.0875\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0876 - val_loss: 0.0874\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0876 - val_loss: 0.0867\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0873 - val_loss: 0.0867\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0871 - val_loss: 0.0862\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0868 - val_loss: 0.0862\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0865 - val_loss: 0.0861\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0863 - val_loss: 0.0858\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0860 - val_loss: 0.0855\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0859 - val_loss: 0.0851\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0857 - val_loss: 0.0850\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0855 - val_loss: 0.0847\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0854 - val_loss: 0.0848\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0852 - val_loss: 0.0844\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0852 - val_loss: 0.0843\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0848 - val_loss: 0.0842\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0846 - val_loss: 0.0841\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0843 - val_loss: 0.0838\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0841 - val_loss: 0.0834\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0839 - val_loss: 0.0837\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0837 - val_loss: 0.0837\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0836 - val_loss: 0.0830\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0835 - val_loss: 0.0828\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0831 - val_loss: 0.0829\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0830 - val_loss: 0.0823\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0830 - val_loss: 0.0824\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0829 - val_loss: 0.0823\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0826 - val_loss: 0.0825\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0825 - val_loss: 0.0822\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0825 - val_loss: 0.0820\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0825 - val_loss: 0.0819\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0824 - val_loss: 0.0818\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0818 - val_loss: 0.0817\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0821 - val_loss: 0.0815\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0821 - val_loss: 0.0815\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0818 - val_loss: 0.0813\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0818 - val_loss: 0.0814\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0816 - val_loss: 0.0815\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0815 - val_loss: 0.0813\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0817 - val_loss: 0.0812\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0816 - val_loss: 0.0810\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0813 - val_loss: 0.0811\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0815 - val_loss: 0.0810\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0814 - val_loss: 0.0811\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0813 - val_loss: 0.0812\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0813 - val_loss: 0.0812\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0812 - val_loss: 0.0810\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0811 - val_loss: 0.0808\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0810 - val_loss: 0.0809\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0811 - val_loss: 0.0810\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0809 - val_loss: 0.0807\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0809 - val_loss: 0.0809\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0811 - val_loss: 0.0810\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0808 - val_loss: 0.0807\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0807 - val_loss: 0.0806\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0808 - val_loss: 0.0807\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0809 - val_loss: 0.0805\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0807 - val_loss: 0.0805\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0808 - val_loss: 0.0806\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0808 - val_loss: 0.0804\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0808 - val_loss: 0.0808\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0805 - val_loss: 0.0806\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0806 - val_loss: 0.0805\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0807 - val_loss: 0.0804\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0809 - val_loss: 0.0806\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0805 - val_loss: 0.0806\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0806 - val_loss: 0.0805\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0806 - val_loss: 0.0801\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0806 - val_loss: 0.0802\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0804 - val_loss: 0.0804\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0804 - val_loss: 0.0804\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0805 - val_loss: 0.0807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24041038a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = keras.Input(shape=(784,))\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in real life, autoencoders applied to images are always convolutional autoencoders\n",
    "# the encoder = stack of Conv2D and MaxPooling2D layers\n",
    "# the decoder = stack of Conv2D and UpSampling2D layers\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train it\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 54s 114ms/step - loss: 0.3206 - val_loss: 0.1544\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 0.1484 - val_loss: 0.1334\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 65s 140ms/step - loss: 0.1318 - val_loss: 0.1239\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 60s 128ms/step - loss: 0.1236 - val_loss: 0.1179\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.1179 - val_loss: 0.1142\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 0.1143 - val_loss: 0.1115\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 58s 125ms/step - loss: 0.1122 - val_loss: 0.1096\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.1105 - val_loss: 0.1080\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 60s 128ms/step - loss: 0.1086 - val_loss: 0.1071\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 0.1074 - val_loss: 0.1054\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 59s 127ms/step - loss: 0.1065 - val_loss: 0.1045\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 60s 127ms/step - loss: 0.1055 - val_loss: 0.1035\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 0.1046 - val_loss: 0.1026\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 58s 124ms/step - loss: 0.1036 - val_loss: 0.1018\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 58s 125ms/step - loss: 0.1029 - val_loss: 0.1013\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 59s 125ms/step - loss: 0.1021 - val_loss: 0.1007\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 57s 121ms/step - loss: 0.1019 - val_loss: 0.1003\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.1014 - val_loss: 0.0999\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 59s 127ms/step - loss: 0.1009 - val_loss: 0.0994\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 52s 112ms/step - loss: 0.1004 - val_loss: 0.0989\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 52s 110ms/step - loss: 0.0999 - val_loss: 0.0985\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.0998 - val_loss: 0.0982\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 59s 127ms/step - loss: 0.0993 - val_loss: 0.0982\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 0.0992 - val_loss: 0.0980\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.0987 - val_loss: 0.0973\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 53s 113ms/step - loss: 0.0986 - val_loss: 0.0970\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.0982 - val_loss: 0.0970\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.0979 - val_loss: 0.0971\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.0977 - val_loss: 0.0970\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 53s 112ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 51s 109ms/step - loss: 0.0970 - val_loss: 0.0958\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 52s 110ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 57s 121ms/step - loss: 0.0967 - val_loss: 0.0954\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.0966 - val_loss: 0.0955\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 51s 109ms/step - loss: 0.0961 - val_loss: 0.0951\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 52s 111ms/step - loss: 0.0961 - val_loss: 0.0949\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 53s 112ms/step - loss: 0.0959 - val_loss: 0.0945\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 52s 112ms/step - loss: 0.0958 - val_loss: 0.0945\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 54s 114ms/step - loss: 0.0957 - val_loss: 0.0947\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.0955"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_img, encoded)\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape((4, 4 * 8)).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to image denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate synthetic noisy digits --> apply a gaussian noise matrix and clip the images between 0-1\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# show the noisy digits\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a slightly different model with more filters per layer\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# At this point the representation is (7, 7, 32)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the autoencoder\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if inputs are sequences, instead of vectors or 2D images\n",
    "# to build a LSTM-based autoencoder\n",
    "    # 1. use a LSTM encoder to turn the input sequences into a single vector containing info about the entire sequence\n",
    "            # then repreat this vector n times (n = # of timesteps in the output sequence)\n",
    "    # 2. run a LSTM decoder to turn this constant sequence into the target sequence\n",
    "\n",
    "timesteps = ...  # Length of your sequences\n",
    "input_dim = ... \n",
    "latent_dim = ...\n",
    "\n",
    "inputs = keras.Input(shape=(timesteps, input_dim))\n",
    "encoded = layers.LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = layers.RepeatVector(timesteps)(encoded)\n",
    "decoded = layers.LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = keras.Model(inputs, decoded)\n",
    "encoder = keras.Model(inputs, encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoendoer (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a type of autoencoder with added constraints on the encoded representations being learned\n",
    "    # it learns a latent variable model for its input data\n",
    "    # turns the input samples x into 2 parameters in a latent space --> z_mean and z_log_sigma\n",
    "    # then randomly sample similar points z from the latent normal distribution that generates the data through z = z_mean + exp(z_log_sigma) * episilon (a random normal tensor)\n",
    "    # decoder network maps the latent space points back to the original input data\n",
    "    # parameters are trained through 2 loss functions\n",
    "        # reconstruction loss forces the decoded samples to match the initial inputs\n",
    "        # KL divergence between learned latent and prior distributions as a regularization term\n",
    "\n",
    "# encoder network: maps inputs to latent distribution parameters\n",
    "original_dim = 28 * 28\n",
    "intermediate_dim = 64\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)\n",
    "\n",
    "# use parameters to sample new similar points from latent space\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "# map sampled latent points back to reconstructed inputs\n",
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "# train the model with a custom loss function: sum of a reconstruction term and the KL divergence regularization term\n",
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# train VAE on MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, x_test))\n",
    "\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new digits\n",
    "# Display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# We will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
